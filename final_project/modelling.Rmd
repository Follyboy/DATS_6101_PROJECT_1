---
title: "Modelling"
author: "Team 6"
date: "2022-11-24"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Importing the required libraries
```{r}
library(caret)
library(dplyr)
library(lessR)
```


##Loading both the datasets 
```{r results='markup'}
beforeSMOTE <- data.frame(read.csv("beforeSmote.csv"))
afterSMOTE <- data.frame(read.csv("afterSmote.csv"))

```

##Factoring the Categorical variables as before 
```{r results='markup'}
#factoring the dataset
beforeSMOTE$gender = factor(beforeSMOTE$gender)
beforeSMOTE$hypertension = factor(beforeSMOTE$hypertension)
beforeSMOTE$heart_disease = factor(beforeSMOTE$heart_disease)
beforeSMOTE$ever_married = factor(beforeSMOTE$ever_married)
beforeSMOTE$work_type = factor(beforeSMOTE$work_type)
beforeSMOTE$Residence_type = factor(beforeSMOTE$Residence_type)
beforeSMOTE$smoking_status = factor(beforeSMOTE$smoking_status)
beforeSMOTE$stroke = factor(beforeSMOTE$stroke)
summary(beforeSMOTE)

#factoring the dataset
afterSMOTE$gender = factor(afterSMOTE$gender)
afterSMOTE$hypertension = factor(afterSMOTE$hypertension)
afterSMOTE$heart_disease = factor(afterSMOTE$heart_disease)
afterSMOTE$ever_married = factor(afterSMOTE$ever_married)
afterSMOTE$work_type = factor(afterSMOTE$work_type)
afterSMOTE$Residence_type = factor(afterSMOTE$Residence_type)
afterSMOTE$smoking_status = factor(afterSMOTE$smoking_status)
afterSMOTE$stroke = factor(afterSMOTE$stroke)
summary(afterSMOTE)

cols <-  hcl.colors(length(levels(beforeSMOTE$stroke)), "Fall")
PieChart(stroke, data = beforeSMOTE, hole = 0,
         fill = cols,
         labels_cex = 0.6)
```

### After SMOTE
```{r}
cols <-  hcl.colors(length(levels(afterSMOTE$stroke)), "Fall")
PieChart(stroke, data = afterSMOTE, hole = 0,
         fill = cols,
         labels_cex = 0.6)
```


## Setting the variable for checking 
```{r}
#set it to beforeSMOTE/afterSMOTE

#modellingDataset <- beforeSMOTE
modellingDataset <- afterSMOTE
```


## Splitting the dataset into train and test 
```{r}
set.seed(123)  
split1<- sample(c(rep(0, 0.7 * nrow(modellingDataset)), rep(1, 0.3 * nrow(modellingDataset))))
table(split1) 
#train split
train <- modellingDataset[split1 == 0, ]
#test split
test <- modellingDataset[split1== 1, ] 
```

###Logistic Regression
```{r results='markup'}
# fit logistic regression model 
logitModel <- glm(stroke~ gender+hypertension+ever_married+smoking_status+avg_glucose_level, 
                        data = train, 
                        family = binomial())

summary(logitModel)
```
```{r results }
# prediction
train$prediction <- predict( logitModel, newdata = train, type = "response" )
test$prediction  <- predict( logitModel, newdata = test , type = "response" )

# distribution of the prediction score grouped by known outcome
ggplot( test, aes( prediction, color = as.factor(stroke) ) ) + 
geom_density( size = 1 ) +
ggtitle( "Testing Set's Predicted Score" ) #+ 
#scale_color_economist( name = "data", labels = c( "negative", "positive" ) ) + 
#theme_economist()
```



```{r }
# Useful functions when working with logistic regression
library(ROCR)
library(grid)
library(caret)
library(dplyr)
library(scales)
library(ggplot2)
library(gridExtra)
library(data.table)

# ------------------------------------------------------------------------------------------
# [AccuracyCutoffInfo] : 
# Obtain the accuracy on the trainining and testing dataset.
# for cutoff value ranging from .4 to .8 ( with a .05 increase )
# @train   : your data.table or data.frame type training data ( assumes you have the predicted score in it ).
# @test    : your data.table or data.frame type testing data
# @predict : prediction's column name (assumes the same for training and testing set)
# @actual  : actual results' column name
# returns  : 1. data : a data.table with three columns.
#            		   each row indicates the cutoff value and the accuracy for the 
#            		   train and test set respectively.
# 			 2. plot : plot that visualizes the data.table

AccuracyCutoffInfo <- function( train, test, predict, actual )
{
	# change the cutoff value's range as you please 
	cutoff <- seq( .4, .8, by = .05 )

	accuracy <- lapply( cutoff, function(c)
	{
		# use the confusionMatrix from the caret package
	  data_train <- as.factor( as.numeric( train[[predict]] > c ) )
		cm_train <- confusionMatrix(data_train, as.factor(train[[actual]]) )
		data_test <- as.factor( as.numeric( test[[predict]] > c ) )
		cm_test  <- confusionMatrix( data_test, as.factor(test[[actual]]) )
			
		dt <- data.table( cutoff = c,
						  train  = cm_train$overall[["Accuracy"]],
		 			      test   = cm_test$overall[["Accuracy"]] )
		return(dt)
	}) %>% rbindlist()

	# visualize the accuracy of the train and test set for different cutoff value 
	# accuracy in percentage.
	accuracy_long <- gather( accuracy, "data", "accuracy", -1 )
	
	plot <- ggplot( accuracy_long, aes( cutoff, accuracy, group = data, color = data ) ) + 
			geom_line( size = 1 ) + geom_point( size = 3 ) +
			scale_y_continuous( label = percent ) +
			ggtitle( "Train/Test Accuracy for Different Cutoff" )

	return( list( data = accuracy, plot = plot ) )
	
	
}
```

```{r}
AccuracyCutoffInfo( train = train_data, test = test_data, 
                                     predict = "prediction", actual = "stroke" )

```


Confusion Matrix plots at different accuracy
```{r}
ConfusionMatrixInfo <- function( data, predict, actual, cutoff )
{	
	# extract the column ;
	# relevel making 1 appears on the more commonly seen position in 
	# a two by two confusion matrix	
	predict <- data[[predict]]
	actual  <- relevel( as.factor( data[[actual]] ), "1" )
	
	result <- data.table( actual = actual, predict = predict )

	# calculating each pred falls into which category for the confusion matrix
	result[ , type := ifelse( predict >= cutoff & actual == 1, "TP",
					  ifelse( predict >= cutoff & actual == 0, "FP", 
					  ifelse( predict <  cutoff & actual == 1, "FN", "TN" ) ) ) %>% as.factor() ]

	# jittering : can spread the points along the x axis 
	plot <- ggplot( result, aes( actual, predict, color = type ) ) + 
			geom_violin( fill = "white", color = NA ) +
			geom_jitter( shape = 1 ) + 
			geom_hline( yintercept = cutoff, color = "blue", alpha = 0.6 ) + 
			scale_y_continuous( limits = c( 0, 1 ) ) + 
			scale_color_discrete( breaks = c( "TP", "FN", "FP", "TN" ) ) + # ordering of the legend 
			guides( col = guide_legend( nrow = 2 ) ) + # adjust the legend to have two rows  
			ggtitle( sprintf( "Confusion Matrix with Cutoff at %.2f", cutoff ) )

	return( list( data = result, plot = plot ) )
}

```

```{r results='markup'}
library(data.table)
library(caret)
# visualize .6 cutoff (lowest point of the previous plot)
cm_info <- ConfusionMatrixInfo( data = test, predict = "prediction", 
                                actual = "stroke", cutoff = .6 )
#ggthemr("flat")
cm_info$plot
```

```{r}
summary(train)

```

Significant variables in case of beforeSMOTE 

* age 
* hypertension 
* heart_disease 
* avg_glucose_level 

Significant variables after applying SMOTE

* genderMale
* age
* hypertension1
* heart_disease1
* work_typeGovt_job
* smoking_statussmokes

#Predicting accuracy 
```{r }
logitModelPred <- predict(logitModel, test, type = "response")
# plot of probabilities
plot(logitModelPred, 
     main = "Scatterplot of Probabilities of stroke (test data)", 
     xlab = "Patients ", ylab = "Predicted Probability of stroke")
```

### Deciding the cut off level 
```{r results}
# setting the cut-off probablity
# function to print confusion matrices for diffrent cut-off levels of probability
#to get confusion matrix checking the max probability from the graph
max_prob <- 0.3
min_prob <- 0.001

CmFn <- function(cutoff) {

       # predicting the test set results
         logitModelPred <- predict(logitModel, test, type = "response")
         C1 <- ifelse(logitModelPred > cutoff, 1, 0)
         C2 <- test$stroke
         predY   <- as.factor(C1)
         actualY <- as.factor(C2)

        # use the confusionMatrix 
        cm1 <-confusionMatrix(table(predY,actualY))
        print(cutoff)
        print(cm1$table)
        # extracting accuracy
        Accuracy <- cm1$overall[1]
        print(Accuracy)
        # extracting sensitivity
          Sensitivity <- cm1$byClass[1]
        # extracting specificity
          Specificity <- cm1$byClass[2]
      # extracting value of kappa
          Kappa <- cm1$overall[2]

        # combined table
          tab <- cbind(cutoff,Accuracy,Sensitivity,Specificity,Kappa)
        return(tab)}
# making sequence of cut-off probabilities       
cutoff1 <- seq( min_prob, max_prob, by = .05 )
# loop using "lapply"
tab2    <- lapply(cutoff1, CmFn)
#tab2
       
```

#ROC Curve
```{r}
# loading the package
#library(ROCR)

library(pROC)
#loadPkg("pROC") # receiver operating characteristic curve, gives the diagnostic ability of a binary classifier system as its discrimination threshold is varied. The curve is on sensitivity/recall/true-positive-rate vs false_alarm/false-positive-rate/fall-out.
prob=predict(logitModel,test, type = "response")
#Admit$prob=prob
h <- roc(stroke~prob, data=test)
auc(h) # area-under-curve prefer 0.8 or higher.
plot(h)
```

Standardization

```{r results='markup'}

```
```{r results='markup'}
train
```

```{r results='markup'}
numeric <- select(train, age, avg_glucose_level, bmi)
pc <- prcomp(numeric,
             center = TRUE,
            scale. = TRUE)
#numeric_test <- select(test, age, avg_glucose_level, bmi)
#pc_test <- prcomp(numeric_test,
#             center = TRUE,
#            scale. = TRUE)
#attributes(pc)
```

Converting  
```{r results='markup'}
#summary(pc)
pc_train <- predict(pc, train)
pc_test <- predict(pc,test)
pc_train <- data.frame(pc_train, train['stroke'])
pc_test <- data.frame(pc_test, test['stroke'])
```

```{r results='markup'}
pc_model <-  logitModel <- glm(stroke~ ., 
                        data = pc_train, 
                        family = binomial())
summary(pc_model)
```


```{r results='markup'}
prob=predict(pc_model,pc_test, type = "response")
h <- roc(stroke~prob, data=pc_test)
auc(h) # area-under-curve prefer 0.8 or higher.
plot(h)
```


#Predicting accuracy on PCA model
```{r }
logitModelPred <- predict(pc_model, pc_test, type = "response")
# plot of probabilities
plot(logitModelPred, 
     main = "Scatterplot of Probabilities of stroke (test data)", 
     xlab = "Patients", ylab = "Predicted Probability of stroke")
```

### Deciding the cut off level for PCA
```{r results}
# setting the cut-off probablity
# function to print confusion matrices for different cut-off levels of probability
#to get confusion matrix checking the max probability from the graph
max_prob <- 0.15
min_prob <- 0.001

CmFn <- function(cutoff) {

       # predicting the test set results
         logitModelPred <- predict(pc_model, pc_test, type = "response")
         C1 <- ifelse(logitModelPred > cutoff, 1, 0)
         C2 <- pc_test$stroke
         predY   <- as.factor(C1)
         actualY <- as.factor(C2)
         print(head(predY))
         print(head(actualY))
        # use the confusionMatrix 
        cm1 <-confusionMatrix(table(predY,actualY))
        print(cutoff)
        print(cm1$table)
        # extracting accuracy
        Accuracy <- cm1$overall[1]
        print(Accuracy)
        # extracting sensitivity
          Sensitivity <- cm1$byClass[1]
        # extracting specificity
          Specificity <- cm1$byClass[2]
      # extracting value of kappa
          Kappa <- cm1$overall[2]

        # combined table
          tab <- cbind(cutoff,Accuracy,Sensitivity,Specificity,Kappa)
        return(tab)}
# making sequence of cut-off probabilities       
cutoff1 <- seq( min_prob, max_prob, by = .05 )
# loop using "lapply"
tab2    <- lapply(cutoff1, CmFn)
tab2
       
```
